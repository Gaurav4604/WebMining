{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "virtualenv",
   "display_name": "virtualEnv",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bfs concurrency\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "import re\n",
    "import concurrent.futures\n",
    "from urllib import request\n",
    "\n",
    "def bfs(url):\n",
    "    visited = set([url])\n",
    "    dq = deque([[url, \"\", 0]])\n",
    "    max_depth = 3\n",
    "    max_breadth = 5\n",
    "    string = \"\"\n",
    "    return_string =\"\"\n",
    "    while dq:\n",
    "        base, path, depth = dq.popleft()\n",
    "        if depth < max_depth:\n",
    "            try:\n",
    "                soup = BeautifulSoup(requests.get(base + path).text, \"html.parser\")\n",
    "                links = soup.find_all(\"a\")[:max_breadth]\n",
    "                for link in links:\n",
    "                    href = link.get(\"href\")\n",
    "                    if href not in visited:\n",
    "                        visited.add(href)\n",
    "                        string += (\"  \" * depth + f\"at depth {depth}: {href}\\n\")\n",
    "                        return_string += (href)+' '\n",
    "\n",
    "                        if href.startswith(\"http\") or href.startswith(\"https\"):\n",
    "                            dq.append([href, \"\", depth + 1])\n",
    "                        else:\n",
    "                            dq.append([base, href, depth + 1])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    filename =\"\"\n",
    "    if \"https://\" in url:\n",
    "        filename = re.sub(r\"https://\",\"\",url)\n",
    "        filename = re.sub(r\".com\",\"\",filename)\n",
    "    elif \"http://\" in url:\n",
    "        filename = re.sub(r\"http://\",\"\",url)\n",
    "        filename = re.sub(r\".com\",\"\",filename)\n",
    "\n",
    "    file  = open(\"crawled_links/\"+filename+\".txt\",\"w\")\n",
    "    file.write(string)\n",
    "    file.close()\n",
    "    \n",
    "    return return_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "started\n",
      "files made!\n"
     ]
    }
   ],
   "source": [
    "frontier = [\"http://toscrape.com\", \"https://soundcloud.com\", \"http://reddit.com\", \"https://fc2.com\"]\n",
    "\n",
    "link_string_arr = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(bfs, i) for i in frontier]\n",
    "    print(\"started\")\n",
    "    link_string_arr = [f.result() for f in futures]\n",
    "print(\"files made!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Terms                                        index\n",
       "0        %                        Doc 2  count: 1[155] \n",
       "1        &    Doc 1  count: 1[81] Doc 2  count: 1[848] \n",
       "2        &    Doc 1  count: 1[81] Doc 2  count: 1[848] \n",
       "3       ''  Doc 1  count: 1[909] Doc 2  count: 1[1615] \n",
       "4       ''  Doc 1  count: 1[909] Doc 2  count: 1[1615] \n",
       "...    ...                                          ...\n",
       "2530     “   Doc 1  count: 1[459] Doc 2  count: 1[589] \n",
       "2531     ”   Doc 1  count: 1[843] Doc 2  count: 1[779] \n",
       "2532     ”   Doc 1  count: 1[843] Doc 2  count: 1[779] \n",
       "2533     •                       Doc 2  count: 1[1597] \n",
       "2534     ™                        Doc 2  count: 1[714] \n",
       "\n",
       "[2535 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>%</td>\n      <td>Doc 2  count: 1[155]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&amp;</td>\n      <td>Doc 1  count: 1[81] Doc 2  count: 1[848]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&amp;</td>\n      <td>Doc 1  count: 1[81] Doc 2  count: 1[848]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>''</td>\n      <td>Doc 1  count: 1[909] Doc 2  count: 1[1615]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>''</td>\n      <td>Doc 1  count: 1[909] Doc 2  count: 1[1615]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2530</th>\n      <td>“</td>\n      <td>Doc 1  count: 1[459] Doc 2  count: 1[589]</td>\n    </tr>\n    <tr>\n      <th>2531</th>\n      <td>”</td>\n      <td>Doc 1  count: 1[843] Doc 2  count: 1[779]</td>\n    </tr>\n    <tr>\n      <th>2532</th>\n      <td>”</td>\n      <td>Doc 1  count: 1[843] Doc 2  count: 1[779]</td>\n    </tr>\n    <tr>\n      <th>2533</th>\n      <td>•</td>\n      <td>Doc 2  count: 1[1597]</td>\n    </tr>\n    <tr>\n      <th>2534</th>\n      <td>™</td>\n      <td>Doc 2  count: 1[714]</td>\n    </tr>\n  </tbody>\n</table>\n<p>2535 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "stop_words = set(STOP_WORDS)\n",
    "stop_words = stop_words.union({'.',',','\\'','\\\"','?','{','}','[',']','<','>','(',')','!'})\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "base = 'https://en.wikipedia.org/wiki/'\n",
    "links = ['Web_mining','Data_mining']\n",
    "terms_searched = []\n",
    "# assuming these are the links crawled by the crawler\n",
    "\n",
    "for i in links:\n",
    "    url = base + i\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    data = list(set(word_tokenize(BeautifulSoup(html, 'html.parser').get_text())).difference(stop_words))\n",
    "    # data = set(word_tokenize((BeautifulSoup(requests.urlopen(url).read().decode('utf8')), 'html.parser').get_text())).difference(stop_words)\n",
    "    stemmed = list(set([stemmer.stem(w) for w in data]))\n",
    "    # lemmatized = list(set([lemmatizer.lemmatize(w) for w in data]))\n",
    "    terms_searched.append(stemmed)\n",
    "\n",
    "terms_data = []\n",
    "for i in terms_searched:\n",
    "    for j in i:\n",
    "        terms_data.append(j)\n",
    "\n",
    "terms_data.sort()\n",
    "\n",
    "lister = []\n",
    "for i in terms_data:\n",
    "    bigger = ''\n",
    "    if i in terms_searched[0]:\n",
    "        indices = []\n",
    "        for j in range(len(terms_searched[0])):\n",
    "            if terms_searched[0][j] == i:\n",
    "                indices.append(j)\n",
    "        bigger+= 'Doc 1  count: ' + str(len(indices)) + str(indices) + ' '\n",
    "    if i in terms_searched[1]:\n",
    "        indices = []\n",
    "        for j in range(len(terms_searched[1])):\n",
    "            if terms_searched[1][j] == i:\n",
    "                indices.append(j)\n",
    "        bigger+= 'Doc 2  count: ' + str(len(indices)) + str(indices) + ' '\n",
    "    lister.append(bigger)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Terms\" : terms_data,\n",
    "    \"index\" : lister\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "000011010\n000011011\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def unary(x):\n",
    "    return '0'*(x-1)+'1'\n",
    "\n",
    "def encoder(x, b):\n",
    "    q = math.floor(x/b)\n",
    "    q_encode = unary(q+1)\n",
    "    i = math.floor(math.log2(b))\n",
    "    d = int(2**(i+1))-b\n",
    "    r = x%b\n",
    "    rem = \"\"\n",
    "    if r < d:\n",
    "        rem = bin(r)[2:]\n",
    "        l = len(rem)\n",
    "        if l < i:\n",
    "            rem = '0'*(i - l)+rem\n",
    "    else:\n",
    "        rem = bin(r + d)[2:]\n",
    "        l = len(rem)\n",
    "        if l < i+1:\n",
    "            rem = '0'*(i+1-l) + rem\n",
    "    return q_encode+rem\n",
    "\n",
    "print(encoder(74, 16))\n",
    "print(encoder(50, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "def decode(n, M):\n",
    "    q=len(n.split('1')[0])\n",
    "    b=math.floor(math.log2(M))\n",
    "    k = 2**(b+1)-M\n",
    "    r = int(n[q+1:q+1+b],2)\n",
    "    if r>=k:\n",
    "        r = int(n[q+1:q+1+b+1],2)\n",
    "        r=r-k\n",
    "    x=q*M+r\n",
    "    return x\n",
    "\n",
    "print(decode(\"1111111110010001101\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           Terms  Doc 1  Doc 2  Doc 3  Doc 4  Doc 5  Doc 6\n",
       "0                             11      2      4     16      9      1      3\n",
       "1                  sophisticated      1      0      2      0      0      0\n",
       "2                          links      6      4      5      4      2      4\n",
       "3      doi:10.1145/360402.360406      1      0      0      0      0      0\n",
       "4                   demonstrated      1      0      3      0      0      2\n",
       "...                          ...    ...    ...    ...    ...    ...    ...\n",
       "15125                 management      3      9     11      4      3      7\n",
       "15126                     linked      0      0      0      0      0      1\n",
       "15127                        lab      0      0      0      1      0      1\n",
       "15128              lemmatisation      0      0      0      0      1      1\n",
       "15129                      sinha      0      0      0      0      0      1\n",
       "\n",
       "[15130 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>Doc 1</th>\n      <th>Doc 2</th>\n      <th>Doc 3</th>\n      <th>Doc 4</th>\n      <th>Doc 5</th>\n      <th>Doc 6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11</td>\n      <td>2</td>\n      <td>4</td>\n      <td>16</td>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sophisticated</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>links</td>\n      <td>6</td>\n      <td>4</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>doi:10.1145/360402.360406</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>demonstrated</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15125</th>\n      <td>management</td>\n      <td>3</td>\n      <td>9</td>\n      <td>11</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>15126</th>\n      <td>linked</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15127</th>\n      <td>lab</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15128</th>\n      <td>lemmatisation</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15129</th>\n      <td>sinha</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>15130 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Q4\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "def extract(url):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    string = BeautifulSoup(html, 'html.parser').get_text().lower()\n",
    "    return (list(word_tokenize(string)), string)\n",
    "\n",
    "def store(name, ls):\n",
    "    with open(name,'w') as f:\n",
    "        for item in list(ls):\n",
    "            try:\n",
    "                f.write('%s\\n'%item)\n",
    "            except:\n",
    "                pass\n",
    "def term_maker(ls, filenames):\n",
    "    terms = []\n",
    "    index = 0\n",
    "    for i in ls:\n",
    "        st = set(i).difference(stop_words)\n",
    "        store('extracted_content/'+filenames[index]+'.txt', list(st))\n",
    "        index += 1\n",
    "        terms.append(list(st))\n",
    "    terms = reduce(lambda z,y : z+y, terms)\n",
    "    return terms\n",
    "\n",
    "def counter(tokens, terms):\n",
    "    ls = []\n",
    "    for i in terms:\n",
    "        ls.append(tokens.count(i))\n",
    "    return ls\n",
    "\n",
    "base = 'https://en.wikipedia.org/wiki/'\n",
    "links = ['Web_mining','Data_mining','Artificial_intelligence','Machine_learning','Natural_language_processing','Text_mining']\n",
    "token_list = []\n",
    "for i in links:\n",
    "    token_list.append(extract(base+i)[0])\n",
    "terms = term_maker(token_list, links)\n",
    "bagOfWords = []\n",
    "for i in token_list:\n",
    "    bagOfWords.append(counter(i,terms))\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Terms\" : list(terms),\n",
    "    \"Doc 1\" : bagOfWords[0],     \n",
    "    \"Doc 2\" : bagOfWords[1],     \n",
    "    \"Doc 3\" : bagOfWords[2],     \n",
    "    \"Doc 4\" : bagOfWords[3],     \n",
    "    \"Doc 5\" : bagOfWords[4],     \n",
    "    \"Doc 6\" : bagOfWords[5]    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           Terms     Doc 1     Doc 2     Doc 3     Doc 4  \\\n",
       "0                             11  0.000576  0.000706  0.001458  0.001161   \n",
       "1                  sophisticated  0.000288  0.000000  0.000182  0.000000   \n",
       "2                          links  0.001728  0.000706  0.000456  0.000516   \n",
       "3      doi:10.1145/360402.360406  0.000288  0.000000  0.000000  0.000000   \n",
       "4                   demonstrated  0.000288  0.000000  0.000273  0.000000   \n",
       "...                          ...       ...       ...       ...       ...   \n",
       "15125                 management  0.000864  0.001589  0.001002  0.000516   \n",
       "15126                     linked  0.000000  0.000000  0.000000  0.000000   \n",
       "15127                        lab  0.000000  0.000000  0.000000  0.000129   \n",
       "15128              lemmatisation  0.000000  0.000000  0.000000  0.000000   \n",
       "15129                      sinha  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          Doc 5     Doc 6  \n",
       "0      0.000186  0.000581  \n",
       "1      0.000000  0.000000  \n",
       "2      0.000372  0.000775  \n",
       "3      0.000000  0.000000  \n",
       "4      0.000000  0.000387  \n",
       "...         ...       ...  \n",
       "15125  0.000559  0.001356  \n",
       "15126  0.000000  0.000194  \n",
       "15127  0.000000  0.000194  \n",
       "15128  0.000186  0.000194  \n",
       "15129  0.000000  0.000194  \n",
       "\n",
       "[15130 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>Doc 1</th>\n      <th>Doc 2</th>\n      <th>Doc 3</th>\n      <th>Doc 4</th>\n      <th>Doc 5</th>\n      <th>Doc 6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11</td>\n      <td>0.000576</td>\n      <td>0.000706</td>\n      <td>0.001458</td>\n      <td>0.001161</td>\n      <td>0.000186</td>\n      <td>0.000581</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sophisticated</td>\n      <td>0.000288</td>\n      <td>0.000000</td>\n      <td>0.000182</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>links</td>\n      <td>0.001728</td>\n      <td>0.000706</td>\n      <td>0.000456</td>\n      <td>0.000516</td>\n      <td>0.000372</td>\n      <td>0.000775</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>doi:10.1145/360402.360406</td>\n      <td>0.000288</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>demonstrated</td>\n      <td>0.000288</td>\n      <td>0.000000</td>\n      <td>0.000273</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000387</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15125</th>\n      <td>management</td>\n      <td>0.000864</td>\n      <td>0.001589</td>\n      <td>0.001002</td>\n      <td>0.000516</td>\n      <td>0.000559</td>\n      <td>0.001356</td>\n    </tr>\n    <tr>\n      <th>15126</th>\n      <td>linked</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000194</td>\n    </tr>\n    <tr>\n      <th>15127</th>\n      <td>lab</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000129</td>\n      <td>0.000000</td>\n      <td>0.000194</td>\n    </tr>\n    <tr>\n      <th>15128</th>\n      <td>lemmatisation</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000186</td>\n      <td>0.000194</td>\n    </tr>\n    <tr>\n      <th>15129</th>\n      <td>sinha</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000194</td>\n    </tr>\n  </tbody>\n</table>\n<p>15130 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "def total(ls):\n",
    "    count=0\n",
    "    for i in ls:\n",
    "        if i != 0:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "TF = [[number/total(i) for number in i] for i in bagOfWords]\n",
    "pd.DataFrame({\n",
    "    \"Terms\" : list(terms),\n",
    "    \"Doc 1\" : TF[0],     \n",
    "    \"Doc 2\" : TF[1],     \n",
    "    \"Doc 3\" : TF[2],     \n",
    "    \"Doc 4\" : TF[3],     \n",
    "    \"Doc 5\" : TF[4],     \n",
    "    \"Doc 6\" : TF[5]    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           Terms  IDF value\n",
       "0                             11   0.154151\n",
       "1                  sophisticated   1.252763\n",
       "2                          links   0.154151\n",
       "3      doi:10.1145/360402.360406   1.945910\n",
       "4                   demonstrated   0.847298\n",
       "...                          ...        ...\n",
       "15125                 management   0.154151\n",
       "15126                     linked   1.945910\n",
       "15127                        lab   1.252763\n",
       "15128              lemmatisation   1.252763\n",
       "15129                      sinha   1.945910\n",
       "\n",
       "[15130 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>IDF value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11</td>\n      <td>0.154151</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sophisticated</td>\n      <td>1.252763</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>links</td>\n      <td>0.154151</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>doi:10.1145/360402.360406</td>\n      <td>1.945910</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>demonstrated</td>\n      <td>0.847298</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15125</th>\n      <td>management</td>\n      <td>0.154151</td>\n    </tr>\n    <tr>\n      <th>15126</th>\n      <td>linked</td>\n      <td>1.945910</td>\n    </tr>\n    <tr>\n      <th>15127</th>\n      <td>lab</td>\n      <td>1.252763</td>\n    </tr>\n    <tr>\n      <th>15128</th>\n      <td>lemmatisation</td>\n      <td>1.252763</td>\n    </tr>\n    <tr>\n      <th>15129</th>\n      <td>sinha</td>\n      <td>1.945910</td>\n    </tr>\n  </tbody>\n</table>\n<p>15130 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import math\n",
    "def IDF_helper(ls):\n",
    "    total = []\n",
    "    length = len(ls[0])\n",
    "    for i in range(length):\n",
    "        count = 0\n",
    "        for j in range(len(ls)):\n",
    "            value = ls[j][i]\n",
    "            if value != 0:\n",
    "                count += 1\n",
    "        total.append(count)\n",
    "    return total\n",
    "\n",
    "def IDF_calc():\n",
    "    helper = IDF_helper(bagOfWords)\n",
    "    no_of_doc = 6\n",
    "    IDF_ls = []\n",
    "    for i in helper:\n",
    "        IDF_ls.append(math.log((1+no_of_doc)/i))\n",
    "    return IDF_ls\n",
    "pd.DataFrame({\n",
    "    \"Terms\" : list(terms),\n",
    "    \"IDF value\" : IDF_calc()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           Terms     Doc 1     Doc 2     Doc 3     Doc 4  \\\n",
       "0                             11  0.000089  0.000109  0.000225  0.000179   \n",
       "1                  sophisticated  0.000361  0.000000  0.000228  0.000000   \n",
       "2                          links  0.000266  0.000109  0.000070  0.000080   \n",
       "3      doi:10.1145/360402.360406  0.000560  0.000000  0.000000  0.000000   \n",
       "4                   demonstrated  0.000244  0.000000  0.000232  0.000000   \n",
       "...                          ...       ...       ...       ...       ...   \n",
       "15125                 management  0.000133  0.000245  0.000154  0.000080   \n",
       "15126                     linked  0.000000  0.000000  0.000000  0.000000   \n",
       "15127                        lab  0.000000  0.000000  0.000000  0.000162   \n",
       "15128              lemmatisation  0.000000  0.000000  0.000000  0.000000   \n",
       "15129                      sinha  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          Doc 5     Doc 6  \n",
       "0      0.000029  0.000090  \n",
       "1      0.000000  0.000000  \n",
       "2      0.000057  0.000119  \n",
       "3      0.000000  0.000000  \n",
       "4      0.000000  0.000328  \n",
       "...         ...       ...  \n",
       "15125  0.000086  0.000209  \n",
       "15126  0.000000  0.000377  \n",
       "15127  0.000000  0.000243  \n",
       "15128  0.000233  0.000243  \n",
       "15129  0.000000  0.000377  \n",
       "\n",
       "[15130 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>Doc 1</th>\n      <th>Doc 2</th>\n      <th>Doc 3</th>\n      <th>Doc 4</th>\n      <th>Doc 5</th>\n      <th>Doc 6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11</td>\n      <td>0.000089</td>\n      <td>0.000109</td>\n      <td>0.000225</td>\n      <td>0.000179</td>\n      <td>0.000029</td>\n      <td>0.000090</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sophisticated</td>\n      <td>0.000361</td>\n      <td>0.000000</td>\n      <td>0.000228</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>links</td>\n      <td>0.000266</td>\n      <td>0.000109</td>\n      <td>0.000070</td>\n      <td>0.000080</td>\n      <td>0.000057</td>\n      <td>0.000119</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>doi:10.1145/360402.360406</td>\n      <td>0.000560</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>demonstrated</td>\n      <td>0.000244</td>\n      <td>0.000000</td>\n      <td>0.000232</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000328</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15125</th>\n      <td>management</td>\n      <td>0.000133</td>\n      <td>0.000245</td>\n      <td>0.000154</td>\n      <td>0.000080</td>\n      <td>0.000086</td>\n      <td>0.000209</td>\n    </tr>\n    <tr>\n      <th>15126</th>\n      <td>linked</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000377</td>\n    </tr>\n    <tr>\n      <th>15127</th>\n      <td>lab</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000162</td>\n      <td>0.000000</td>\n      <td>0.000243</td>\n    </tr>\n    <tr>\n      <th>15128</th>\n      <td>lemmatisation</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000233</td>\n      <td>0.000243</td>\n    </tr>\n    <tr>\n      <th>15129</th>\n      <td>sinha</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000377</td>\n    </tr>\n  </tbody>\n</table>\n<p>15130 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "def TF_IDF_calc(ls):\n",
    "    IDF = IDF_calc()\n",
    "    for i in range(len(ls[0])):\n",
    "        for j in range(6):\n",
    "                ls[j][i]*=IDF[i]\n",
    "    return ls\n",
    "TF_IDF = TF_IDF_calc(TF)\n",
    "pd.DataFrame({\n",
    "    \"Terms\" : list(terms),\n",
    "    \"Doc 1\" : TF_IDF[0],\n",
    "    \"Doc 2\" : TF_IDF[1],\n",
    "    \"Doc 3\" : TF_IDF[2],\n",
    "    \"Doc 4\" : TF_IDF[3],\n",
    "    \"Doc 5\" : TF_IDF[4],\n",
    "    \"Doc 6\" : TF_IDF[5]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Terms    TF_IDF\n",
       "0         machine  0.154151\n",
       "1           based  0.154151\n",
       "2        learning  0.154151\n",
       "3  communications  1.252763\n",
       "4            want  1.945910"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>TF_IDF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>machine</td>\n      <td>0.154151</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>based</td>\n      <td>0.154151</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>learning</td>\n      <td>0.154151</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>communications</td>\n      <td>1.252763</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>want</td>\n      <td>1.945910</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "def query_TF_IDF(string):\n",
    "    ref_tokens = list(word_tokenize(string.lower()))\n",
    "    tokens = list(set(word_tokenize(string.lower())).difference(stop_words))\n",
    "    Tf_query = []\n",
    "    for i in tokens:\n",
    "        Tf_query.append(1/ref_tokens.count(i))\n",
    "    ref_IDF = IDF_calc()\n",
    "    TF_IDF = []\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in terms:\n",
    "            index = terms.index(tokens[i])\n",
    "            value = ref_IDF[index]*Tf_query[i]\n",
    "            TF_IDF.append(value)\n",
    "        else:\n",
    "            TF_IDF.append(0)\n",
    "    return (tokens,TF_IDF)\n",
    "\n",
    "string = \"I want communications based on machine learning\"\n",
    "Q_TF_IDF = query_TF_IDF(string)\n",
    "pd.DataFrame({\n",
    "    \"Terms\" : Q_TF_IDF[0],\n",
    "    \"TF_IDF\" : Q_TF_IDF[1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           Terms     Doc 1     Doc 2     Doc 3     Doc 4  \\\n",
       "0                             11  0.002804  0.003442  0.002965  0.004997   \n",
       "1                  sophisticated  0.011395  0.000000  0.003012  0.000000   \n",
       "2                          links  0.008413  0.003442  0.000927  0.002221   \n",
       "3      doi:10.1145/360402.360406  0.017700  0.000000  0.000000  0.000000   \n",
       "4                   demonstrated  0.007707  0.000000  0.003056  0.000000   \n",
       "...                          ...       ...       ...       ...       ...   \n",
       "15125                 management  0.004206  0.007745  0.002038  0.002221   \n",
       "15126                     linked  0.000000  0.000000  0.000000  0.000000   \n",
       "15127                        lab  0.000000  0.000000  0.000000  0.004512   \n",
       "15128              lemmatisation  0.000000  0.000000  0.000000  0.000000   \n",
       "15129                      sinha  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          Doc 5     Doc 6  \n",
       "0      0.000866  0.003176  \n",
       "1      0.000000  0.000000  \n",
       "2      0.001732  0.004235  \n",
       "3      0.000000  0.000000  \n",
       "4      0.000000  0.011639  \n",
       "...         ...       ...  \n",
       "15125  0.002598  0.007411  \n",
       "15126  0.000000  0.013365  \n",
       "15127  0.000000  0.008604  \n",
       "15128  0.007038  0.008604  \n",
       "15129  0.000000  0.013365  \n",
       "\n",
       "[15130 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>Doc 1</th>\n      <th>Doc 2</th>\n      <th>Doc 3</th>\n      <th>Doc 4</th>\n      <th>Doc 5</th>\n      <th>Doc 6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11</td>\n      <td>0.002804</td>\n      <td>0.003442</td>\n      <td>0.002965</td>\n      <td>0.004997</td>\n      <td>0.000866</td>\n      <td>0.003176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sophisticated</td>\n      <td>0.011395</td>\n      <td>0.000000</td>\n      <td>0.003012</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>links</td>\n      <td>0.008413</td>\n      <td>0.003442</td>\n      <td>0.000927</td>\n      <td>0.002221</td>\n      <td>0.001732</td>\n      <td>0.004235</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>doi:10.1145/360402.360406</td>\n      <td>0.017700</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>demonstrated</td>\n      <td>0.007707</td>\n      <td>0.000000</td>\n      <td>0.003056</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.011639</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15125</th>\n      <td>management</td>\n      <td>0.004206</td>\n      <td>0.007745</td>\n      <td>0.002038</td>\n      <td>0.002221</td>\n      <td>0.002598</td>\n      <td>0.007411</td>\n    </tr>\n    <tr>\n      <th>15126</th>\n      <td>linked</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.013365</td>\n    </tr>\n    <tr>\n      <th>15127</th>\n      <td>lab</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004512</td>\n      <td>0.000000</td>\n      <td>0.008604</td>\n    </tr>\n    <tr>\n      <th>15128</th>\n      <td>lemmatisation</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007038</td>\n      <td>0.008604</td>\n    </tr>\n    <tr>\n      <th>15129</th>\n      <td>sinha</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.013365</td>\n    </tr>\n  </tbody>\n</table>\n<p>15130 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "def normalization_Document(TF_IDF):\n",
    "    no_of_docs = len(TF_IDF)\n",
    "    for i in range(no_of_docs):\n",
    "        divider = 0\n",
    "        for j in TF_IDF[i]:\n",
    "            divider += j**2\n",
    "        divider = math.sqrt(divider)\n",
    "        TF_IDF[i] = [k/divider for k in TF_IDF[i]]\n",
    "    return TF_IDF\n",
    "\n",
    "normalized = normalization_Document(TF_IDF)\n",
    "pd.DataFrame({\n",
    "    \"Terms\" : list(terms),\n",
    "    \"Doc 1\" : normalized[0],\n",
    "    \"Doc 2\" : normalized[1],\n",
    "    \"Doc 3\" : normalized[2],\n",
    "    \"Doc 4\" : normalized[3],\n",
    "    \"Doc 5\" : normalized[4],\n",
    "    \"Doc 6\" : normalized[5],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Terms    TF_IDF\n",
       "0         machine  0.028403\n",
       "1           based  0.028403\n",
       "2        learning  0.028403\n",
       "3  communications  0.230828\n",
       "4            want  0.358543"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>TF_IDF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>machine</td>\n      <td>0.028403</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>based</td>\n      <td>0.028403</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>learning</td>\n      <td>0.028403</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>communications</td>\n      <td>0.230828</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>want</td>\n      <td>0.358543</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "def normalization_Query(string):\n",
    "    TF_IDF = query_TF_IDF(string)[1]\n",
    "    divider = 0\n",
    "    for i in TF_IDF:\n",
    "        divider += i**2\n",
    "    TF_IDF = [i/divider for i in TF_IDF]\n",
    "    return TF_IDF\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Terms\" : query_TF_IDF(string)[0],\n",
    "    \"TF_IDF\" : normalization_Query(string)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Documents  Cosine Dist\n",
       "0      Doc1     0.005778\n",
       "1      Doc2     0.002249\n",
       "2      Doc3     0.003736\n",
       "3      Doc4     0.007917\n",
       "4      Doc5     0.001648\n",
       "5      Doc6     0.000662"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Documents</th>\n      <th>Cosine Dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Doc1</td>\n      <td>0.005778</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Doc2</td>\n      <td>0.002249</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Doc3</td>\n      <td>0.003736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Doc4</td>\n      <td>0.007917</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Doc5</td>\n      <td>0.001648</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Doc6</td>\n      <td>0.000662</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "def cosine_dist():\n",
    "    TF_IDF_doc = normalization_Document(TF_IDF)\n",
    "    TF_IDF_query = normalization_Query(string)\n",
    "    tokens = Q_TF_IDF[0]\n",
    "    index_ls = []\n",
    "    for i in tokens:\n",
    "        index_ls.append(terms.index(i))\n",
    "    \n",
    "    cosine_dict = {}\n",
    "    for i in range(len(TF_IDF_doc)):\n",
    "        cosine_dist = 0\n",
    "        index = 0\n",
    "        for j in index_ls:\n",
    "            cosine_dist += TF_IDF_doc[i][j]* TF_IDF_query[index]\n",
    "            index+=1\n",
    "        cosine_dict['Doc'+str(i+1)] = cosine_dist\n",
    "    return cosine_dict\n",
    "\n",
    "pd.DataFrame(list(cosine_dist().items()), columns=['Documents', 'Cosine Dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Documents  Euclidean Dist\n",
       "0      Doc1        0.416352\n",
       "1      Doc2        0.427644\n",
       "2      Doc3        0.421194\n",
       "3      Doc4        0.456539\n",
       "4      Doc5        0.426861\n",
       "5      Doc6        0.427928"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Documents</th>\n      <th>Euclidean Dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Doc1</td>\n      <td>0.416352</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Doc2</td>\n      <td>0.427644</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Doc3</td>\n      <td>0.421194</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Doc4</td>\n      <td>0.456539</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Doc5</td>\n      <td>0.426861</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Doc6</td>\n      <td>0.427928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "def euclidean_dist():\n",
    "    TF_IDF_doc = normalization_Document(TF_IDF)\n",
    "    TF_IDF_query = normalization_Query(string)\n",
    "    tokens = Q_TF_IDF[0]\n",
    "    index_ls = []\n",
    "    for i in tokens:\n",
    "        index_ls.append(terms.index(i))\n",
    "    \n",
    "    euclidean_dict = {}\n",
    "    for i in range(len(TF_IDF_doc)):\n",
    "        euclidean_dist = 0\n",
    "        index = 0\n",
    "        for j in index_ls:\n",
    "            euclidean_dist += (TF_IDF_doc[i][j] - TF_IDF_query[index])**2\n",
    "            index+=1\n",
    "        euclidean_dist = math.sqrt(euclidean_dist)\n",
    "        euclidean_dict['Doc'+str(i+1)] = euclidean_dist\n",
    "    return euclidean_dict\n",
    "\n",
    "pd.DataFrame(list(euclidean_dist().items()), columns=['Documents', 'Euclidean Dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      0         1\n",
       "0  Doc4  0.007917\n",
       "1  Doc1  0.005778\n",
       "2  Doc3  0.003736\n",
       "3  Doc2  0.002249\n",
       "4  Doc5  0.001648\n",
       "5  Doc6  0.000662"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Doc4</td>\n      <td>0.007917</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Doc1</td>\n      <td>0.005778</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Doc3</td>\n      <td>0.003736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Doc2</td>\n      <td>0.002249</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Doc5</td>\n      <td>0.001648</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Doc6</td>\n      <td>0.000662</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "sorted_dict = {k: v for k,v in sorted(cosine_dist().items(), key=lambda item: item[1])}\n",
    "\n",
    "pd.DataFrame(list(sorted_dict.items())[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      0         1\n",
       "0  Doc1  0.416352\n",
       "1  Doc3  0.421194\n",
       "2  Doc5  0.426861\n",
       "3  Doc2  0.427644\n",
       "4  Doc6  0.427928\n",
       "5  Doc4  0.456539"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Doc1</td>\n      <td>0.416352</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Doc3</td>\n      <td>0.421194</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Doc5</td>\n      <td>0.426861</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Doc2</td>\n      <td>0.427644</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Doc6</td>\n      <td>0.427928</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Doc4</td>\n      <td>0.456539</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "sorted_dict = {k: v for k,v in sorted(euclidean_dist().items(), key=lambda item: item[1])}\n",
    "\n",
    "pd.DataFrame(list(sorted_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Similarity between  Cosine value\n",
       "0      Doc1 and Doc2      0.369324\n",
       "1      Doc1 and Doc3      0.135916\n",
       "2      Doc1 and Doc4      0.182782\n",
       "3      Doc1 and Doc5      0.145552\n",
       "4      Doc1 and Doc6      0.277352"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Similarity between</th>\n      <th>Cosine value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Doc1 and Doc2</td>\n      <td>0.369324</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Doc1 and Doc3</td>\n      <td>0.135916</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Doc1 and Doc4</td>\n      <td>0.182782</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Doc1 and Doc5</td>\n      <td>0.145552</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Doc1 and Doc6</td>\n      <td>0.277352</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "def doc_similarity():\n",
    "    TF_IDF_doc = normalization_Document(TF_IDF)\n",
    "    len_doc = len(TF_IDF_doc[0])\n",
    "    cosine_sim = []\n",
    "    for i in range(1, len(TF_IDF_doc)):\n",
    "        temp = 0\n",
    "        for j in range(len_doc):\n",
    "            temp += TF_IDF_doc[0][j] * TF_IDF_doc[i][j]\n",
    "        cosine_sim.append(temp)\n",
    "    return cosine_sim\n",
    "\n",
    "ls = [\"Doc1 and Doc2\", \"Doc1 and Doc3\", \"Doc1 and Doc4\", \"Doc1 and Doc5\", \"Doc1 and Doc6\"]\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Similarity between\" : ls,\n",
    "    \"Cosine value\" : doc_similarity()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "Artificial Intelligence Wikipedia\n",
      "\n",
      "\n",
      "predictive typing artifi : ['artificial', 'artificialintelligence', 'artificial_intelligence']\n",
      "\n",
      "predicted by autocorrect : intelligent\n",
      "\n",
      "\n",
      "Machine Learning Wikipedia\n",
      "\n",
      "\n",
      "predictive typing machi : ['machine', 'machines', 'machines[edit]', 'machinery', 'machine_learning']\n",
      "\n",
      "predicted by autocorrect : learn\n"
     ]
    }
   ],
   "source": [
    "def jaccardSimilarity(word1,word2) : \n",
    "    common_words = len(set(set(list(word1))&set(list(word2))))\n",
    "    total_words = len(set(list(word1)+list(word2)))\n",
    "    return common_words/total_words\n",
    "\n",
    "class TrieNode():\n",
    "    def __init__(self): \n",
    "        self.children = {} \n",
    "        self.last = False\n",
    "\n",
    "class Trie(): \n",
    "    \n",
    "    def __init__(self): \n",
    "        self.root = TrieNode() \n",
    "        self.word_list = [] \n",
    "  \n",
    "    def formTrie(self, keys): \n",
    "        for key in keys: \n",
    "            self.insert(key) \n",
    "  \n",
    "    def insert(self, key): \n",
    "        node = self.root \n",
    "  \n",
    "        for a in list(key): \n",
    "            if not node.children.get(a): \n",
    "                node.children[a] = TrieNode() \n",
    "  \n",
    "            node = node.children[a] \n",
    "  \n",
    "        node.last = True\n",
    "  \n",
    "    def suggestionsRec(self, node, word):  #recursive\n",
    "        if node.last: \n",
    "            self.word_list.append(word) \n",
    "  \n",
    "        for a,n in node.children.items(): \n",
    "            self.suggestionsRec(n, word + a) \n",
    "  \n",
    "    def PredictiveTyping(self, key): \n",
    "        node = self.root\n",
    "        temp_word = '' \n",
    "  \n",
    "        for a in list(key): \n",
    "            if not node.children.get(a):\n",
    "                break\n",
    "  \n",
    "            temp_word += a \n",
    "            node = node.children[a] \n",
    "  \n",
    "        self.suggestionsRec(node, temp_word) \n",
    "        return self.word_list\n",
    "    \n",
    "    def autoCorrect(self,key) :\n",
    "        allwords = self.PredictiveTyping(\"\")\n",
    "        highest_jacsims = 0\n",
    "        highest_jacsims_word = allwords[0]\n",
    "        for word in allwords :\n",
    "            temp_sim = jaccardSimilarity(word, key)\n",
    "            if temp_sim > highest_jacsims :\n",
    "                highest_jacsims = temp_sim\n",
    "                highest_jacsims_word = word\n",
    "        return highest_jacsims_word\n",
    "    \n",
    "    def printTrie(self) :\n",
    "        print(str(self.root.children) + \"\\n\")\n",
    "  \n",
    "# Driver Code \n",
    "keys = [\"hello\", \"dog\", \"hell\", \"cat\", \"a\",  \n",
    "        \"hel\", \"help\", \"helps\", \"helping\"] # keys to form the trie structure. \n",
    "key = \"hel\" \n",
    "  \n",
    "\n",
    "#for artificial intelligence link - trie structure\n",
    "\n",
    "print(\"\\n\\nArtificial Intelligence Wikipedia\\n\\n\")\n",
    "raw1 = extract(\"https://en.wikipedia.org/wiki/Artificial_intelligence\")[1]\n",
    "\n",
    "url1_words = re.findall(r'[a-zA-z]+', raw1)\n",
    "\n",
    "STOP_WORDS.update(['.',',', \"'\",'\"' , \"?\", \"[\",\"]\",\"(\",\")\",\"{\",\"}\",\"<\",\">\",\"!\"])\n",
    "\n",
    "url1_nostopwords = [x for x in url1_words if x not in STOP_WORDS]\n",
    "\n",
    "t1 = Trie()  \n",
    "t1.formTrie(url1_nostopwords) \n",
    "# t1.printTrie() \n",
    "predTemp = input()\n",
    "print(\"predictive typing \" + predTemp + \" : \" + str(t1.PredictiveTyping(predTemp)) + \"\\n\")\n",
    "autoTemp = input()\n",
    "print(\"predicted by autocorrect : \"+ str(t1.autoCorrect(autoTemp)))\n",
    "\n",
    "\n",
    "print(\"\\n\\nMachine Learning Wikipedia\\n\\n\")\n",
    "\n",
    "raw2 = extract(\"https://en.wikipedia.org/wiki/Machine_learning\")[1]\n",
    "url2_words = re.findall(r'[a-zA-z]+', raw2)\n",
    "\n",
    "#adding manual stop words to the STOP_WORDS set\n",
    "STOP_WORDS.update(['.',',', \"'\",'\"' , \"?\", \"[\",\"]\",\"(\",\")\",\"{\",\"}\",\"<\",\">\",\"!\"])\n",
    "\n",
    "#removing stop words from url\n",
    "url2_nostopwords = [x for x in url2_words if x not in STOP_WORDS]\n",
    "\n",
    "#creating the trie structure\n",
    "t2 = Trie()  \n",
    "t2.formTrie(url2_nostopwords) \n",
    "# t2.printTrie() \n",
    "predTemp = input()\n",
    "print(\"predictive typing \" + predTemp + \" : \" + str(t2.PredictiveTyping(predTemp)) + \"\\n\")\n",
    "autoTemp = input()\n",
    "print(\"predicted by autocorrect : \"+ str(t1.autoCorrect(autoTemp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'a': <__main__.TrieNode object at 0x00000273B4CEF160>, 'i': <__main__.TrieNode object at 0x00000273B4CEF198>, 'w': <__main__.TrieNode object at 0x00000273B4CEF048>, 'f': <__main__.TrieNode object at 0x00000273B4CEF7B8>, 'e': <__main__.TrieNode object at 0x00000273B4CEF860>, 'j': <__main__.TrieNode object at 0x00000273B4CEFC88>, 'n': <__main__.TrieNode object at 0x00000273B4CEFBA8>, 's': <__main__.TrieNode object at 0x00000273B5F6B940>, 'r': <__main__.TrieNode object at 0x00000273B5F6BC88>, 'u': <__main__.TrieNode object at 0x00000273B5F6B0B8>, 'd': <__main__.TrieNode object at 0x00000273B5F6B0F0>, 'm': <__main__.TrieNode object at 0x00000273B5F6BBA8>, 'o': <__main__.TrieNode object at 0x00000273B5F6BF98>, 'g': <__main__.TrieNode object at 0x00000273B68CADA0>, 'k': <__main__.TrieNode object at 0x00000273B68CABE0>, 'p': <__main__.TrieNode object at 0x00000273B68CA7F0>, 'l': <__main__.TrieNode object at 0x00000273B68CA4A8>, 'c': <__main__.TrieNode object at 0x00000273B5BF0BE0>, 'v': <__main__.TrieNode object at 0x00000273B36204E0>, 'b': <__main__.TrieNode object at 0x00000273B3DFEDA0>, 't': <__main__.TrieNode object at 0x00000273B385DDD8>, 'h': <__main__.TrieNode object at 0x00000273B38AA1D0>, 'q': <__main__.TrieNode object at 0x00000273B3899978>, 'y': <__main__.TrieNode object at 0x00000273B362D1D0>, ']': <__main__.TrieNode object at 0x00000273B362D860>, 'x': <__main__.TrieNode object at 0x00000273B387DB00>, '[': <__main__.TrieNode object at 0x00000273ABB63E80>, 'z': <__main__.TrieNode object at 0x00000273B617B080>, '^': <__main__.TrieNode object at 0x00000273B3739B38>, '_': <__main__.TrieNode object at 0x00000273B3A05550>}\n\n"
     ]
    }
   ],
   "source": [
    "t1.printTrie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'m': <__main__.TrieNode object at 0x00000273B6122780>, 'l': <__main__.TrieNode object at 0x00000273B63DF860>, 'w': <__main__.TrieNode object at 0x00000273B63DFC50>, 'f': <__main__.TrieNode object at 0x00000273B63DFB00>, 'e': <__main__.TrieNode object at 0x00000273B63DF940>, 'j': <__main__.TrieNode object at 0x00000273B63DF550>, 'n': <__main__.TrieNode object at 0x00000273B63DF630>, 's': <__main__.TrieNode object at 0x00000273B63DFB38>, 'a': <__main__.TrieNode object at 0x00000273B63DF978>, 'i': <__main__.TrieNode object at 0x00000273B5F6B518>, 'r': <__main__.TrieNode object at 0x00000273B345B400>, 'o': <__main__.TrieNode object at 0x00000273B37C7A58>, 'p': <__main__.TrieNode object at 0x00000273B37C7278>, 'c': <__main__.TrieNode object at 0x00000273B37C7B70>, 'd': <__main__.TrieNode object at 0x00000273B453AC88>, 'u': <__main__.TrieNode object at 0x00000273B364BA58>, 'g': <__main__.TrieNode object at 0x00000273B364B8D0>, 't': <__main__.TrieNode object at 0x00000273B364B780>, 'b': <__main__.TrieNode object at 0x00000273B47FB7F0>, 'k': <__main__.TrieNode object at 0x00000273B47FB588>, 'v': <__main__.TrieNode object at 0x00000273B43560F0>, 'h': <__main__.TrieNode object at 0x00000273B4670EF0>, 'q': <__main__.TrieNode object at 0x00000273B49E1E48>, ']': <__main__.TrieNode object at 0x00000273B63FFBE0>, 'y': <__main__.TrieNode object at 0x00000273B67FF320>, 'z': <__main__.TrieNode object at 0x00000273B685ED68>, '\\\\': <__main__.TrieNode object at 0x00000273B4CAF1D0>, 'x': <__main__.TrieNode object at 0x00000273B684BB00>, '^': <__main__.TrieNode object at 0x00000273B681BB38>, '_': <__main__.TrieNode object at 0x00000273B682C048>, '[': <__main__.TrieNode object at 0x00000273B65341D0>}\n\n"
     ]
    }
   ],
   "source": [
    "t2.printTrie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}